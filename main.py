import os
import json
import firebase_admin
from firebase_admin import credentials, firestore
from dotenv import load_dotenv
from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
from typing import List, Optional

from google import genai
from google.genai import types
from google.cloud.firestore_v1.vector import Vector
from google.cloud.firestore_v1.base_vector_query import DistanceMeasure

# --- 0. LOAD BI·∫æN M√îI TR∆Ø·ªúNG ---
load_dotenv()

# --- 1. C·∫§U H√åNH FASTAPI & CORS ---
app = FastAPI(title="FPTU RAG Backend")

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_methods=["*"],
    allow_headers=["*"],
)

# --- 2. KH·ªûI T·∫†O D·ªäCH V·ª§ ---

if not firebase_admin._apps:
    fb_config = os.getenv("FIREBASE_CONFIG")
    if fb_config:
        cred = credentials.Certificate(json.loads(fb_config))
    else:
        cred_path = os.getenv("FIREBASE_SERVICE_ACCOUNT", "service-account.json")
        cred = credentials.Certificate(cred_path)
    firebase_admin.initialize_app(cred)

db = firestore.client()

# Kh·ªüi t·∫°o Gemini Client
client = genai.Client(api_key=os.getenv("GEMINI_API_KEY"))
MODEL_ID = "gemini-2.5-flash"
# CH·ªàNH MODEL: Kh·ªõp v·ªõi model b·∫°n d√πng ƒë·ªÉ upload
MODEL_EMBED = "gemini-embedding-001"

# --- 3. MENU ƒê·ªäNH TUY·∫æN (GI·ªÆ NGUY√äN 100%) ---
SEARCH_KEYS_MENU = {
    "V1": "thi ti·∫øng anh ƒë·∫ßu v√†o, x·∫øp l·ªõp, ielts 6.0, mi·ªÖn h·ªçc d·ª± b·ªã, c·∫•u tr√∫c ƒë·ªÅ thi, writing skill",
    "V2": "l·ªô tr√¨nh luk global, hurricane, greenfire, heatwave, thunderbolt, debate, thuy·∫øt tr√¨nh",
    "V3": "summit 1 summit 2, top notch, progress test pt, assignment m√¥n ent, thi seb eos",
    "V4": "m·∫πo pass m√¥n ti·∫øng anh, c√°ch d√πng edunext fap, ki·ªÉm tra ƒëi·ªÉm danh, writing speaking assignment",
    "V5": "h·ªçc nh·∫°c c·ª• d√¢n t·ªôc, ƒë√†n b·∫ßu, ƒë√†n tranh, s√°o tr√∫c, ƒë·ªãa ch·ªâ mua nh·∫°c c·ª• h·∫£o vƒ©nh ƒë√† n·∫µng",
    "V6": "h·ªçc vovinam fpt, clb vovinam vvc, thi l√™n ƒëai, v√µ nh·∫°c, gi·∫£i kh∆°i ngu·ªìn v√µ vi·ªát",
    "V7": "kinh nghi·ªám ƒëi qu√¢n s·ª±, ƒë·ªì d√πng t√¢n binh, l√≥t gi√†y, ph·∫•n r√¥m, g·∫•p chƒÉn b√°nh ch∆∞ng, n·ªôi v·ª•",
    "V8": "review campus fpt ƒë√† n·∫µng, t√≤a nh√† alpha gamma, th∆∞ vi·ªán, fpt city ng≈© h√†nh s∆°n",
    "V9": "so s√°nh k√Ω t√∫c x√° v√† tr·ªç, ∆∞u nh∆∞·ª£c ƒëi·ªÉm ktx fpt, an ninh n·ªôi tr√∫, chi ph√≠ ·ªü tr·ªç",
    "V10": "c·∫©m nang thu√™ tr·ªç ƒë√† n·∫µng, l·ª´a ƒë·∫£o ti·ªÅn c·ªçc, h·ª£p ƒë·ªìng thu√™ nh√†, t√¨m b·∫°n ·ªü gh√©p",
    "V11": "qu√°n ƒÉn ngon fpt ƒë√† n·∫µng, cafe h·ªçc b√†i, zone six 24/7, c∆°m g√† x·∫£ x·ªá, b√∫n ƒë·∫≠u 1996",
    "V12": "link fap flm, t·∫£i ph·∫ßn m·ªÅm thi seb eos, l·ªói k·ªπ thu·∫≠t, checkout e360, c√†i ƒë·∫∑t ph·∫ßn m·ªÅm",
    "V13": "qu·∫£n l√Ω th·ªùi gian, th√≥i quen ng·ªß, xem tr∆∞·ªõc b√†i, check attendance fap, k·ªπ nƒÉng t·ª± h·ªçc"
}

# --- 4. C·∫§U TR√öC D·ªÆ LI·ªÜU ---
class ChatMessage(BaseModel):
    role: str
    content: str

class ChatRequest(BaseModel):
    message: str
    history: Optional[List[ChatMessage]] = []

# --- 5. LOGIC X·ª¨ L√ù CH√çNH ---

def get_semantic_search_query(user_raw_query, history):
    menu_str = "\n".join([f"- {k}: {v}" for k, v in SEARCH_KEYS_MENU.items()])
    context_recent = f"Ng·ªØ c·∫£nh l·ªãch s·ª≠: {history[-1].content}" if history else ""

    prompt = f"""B·∫°n l√† b·ªô ƒë·ªãnh tuy·∫øn d·ªØ li·ªáu cho sinh vi√™n FPTU.
    Nhi·ªám v·ª•: Ph√¢n t√≠ch c√¢u h·ªèi v√† ch·ªçn ra B·ªò KEYWORD ph√π h·ª£p nh·∫•t.
    DANH S√ÅCH KEYWORDS:
    {menu_str}
    {context_recent}
    C√ÇU H·ªéI NG∆Ø·ªúI D√ôNG: "{user_raw_query}"
    Y√äU C·∫¶U: CH·ªà TR·∫¢ V·ªÄ chu·ªói keyword t∆∞∆°ng ·ª©ng ho·∫∑c c√¢u h·ªèi g·ªëc. Kh√¥ng gi·∫£i th√≠ch."""

    try:
        response = client.models.generate_content(model=MODEL_ID, contents=prompt)
        return response.text.strip()
    except:
        return user_raw_query

@app.post("/chat")
async def chat_endpoint(req: ChatRequest):
    try:
        # B∆Ø·ªöC 1: ROUTING (GI·ªÆ NGUY√äN LOGIC)
        search_query = get_semantic_search_query(req.message, req.history)
        print(f"üéØ Router ƒë√£ ch·ªçn: {search_query}")

        # B∆Ø·ªöC 2: TRUY XU·∫§T VECTOR
        # CH·ªàNH: dimensionality=1536 ƒë·ªÉ kh·ªõp v·ªõi Index b·∫°n v·ª´a t·∫°o
        embed_res = client.models.embed_content(
            model=MODEL_EMBED,
            contents=search_query,
            config={'output_dimensionality': 1536}
        )
        query_vector = embed_res.embeddings[0].values

        # CH·ªàNH: ƒê·ªïi t√™n collection th√†nh fpt_handbook_v1
        results = db.collection("fpt_handbook_v1").find_nearest(
            vector_field="embedding",
            query_vector=Vector(query_vector),
            distance_measure=DistanceMeasure.COSINE,
            limit=1
        ).get()

        if not results:
            return {"reply": "ü§ñ Bot: Xin l·ªói, m√¨nh kh√¥ng t√¨m th·∫•y d·ªØ li·ªáu li√™n quan."}

        top_result = results[0]
        context = top_result.to_dict().get('content', 'Kh√¥ng c√≥ n·ªôi dung')
        dist = getattr(top_result, 'distance', 0) or 0
        print(f"üìä Distance: {dist:.4f}")

        # GI·ªÆ NGUY√äN TH√îNG S·ªê 0.6
        if dist > 0.6:
            return {"reply": "ü§ñ Bot: C√¢u h·ªèi n√†y n·∫±m ngo√†i ph·∫°m vi c·∫©m nang sinh vi√™n FPTU."}

        # B∆Ø·ªöC 3: GENERATION (GI·ªÆ NGUY√äN LOGIC)
        system_instruction = "B·∫°n l√† tr·ª£ l√Ω ·∫£o th√¥ng minh cho sinh vi√™n ƒê·∫°i h·ªçc FPT ƒê√† N·∫µng. Tr·∫£ l·ªùi th√¢n thi·ªán, ng·∫Øn g·ªçn, c√≥ icon."

        response = client.models.generate_content(
            model=MODEL_ID,
            contents=f"TH√îNG TIN C·∫®M NANG: {context}\n\nC√ÇU H·ªéI: {req.message}",
            config=types.GenerateContentConfig(
                system_instruction=system_instruction,
                temperature=0.4,
            )
        )

        return {"reply": response.text}

    except Exception as e:
        print(f"L·ªói: {e}")
        raise HTTPException(status_code=500, detail=str(e))

if __name__ == "__main__":
    import uvicorn
    port = int(os.environ.get("PORT", 10000))
    uvicorn.run(app, host="0.0.0.0", port=port)