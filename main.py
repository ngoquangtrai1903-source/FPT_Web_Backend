import os
import json
import firebase_admin
from firebase_admin import credentials, firestore
from dotenv import load_dotenv
from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
from typing import List, Optional

# ThÆ° viá»‡n AI vÃ  Vector Search (Dá»±a trÃªn logic báº¡n cung cáº¥p)
from sentence_transformers import SentenceTransformer
from google.cloud.firestore_v1.vector import Vector
from google.cloud.firestore_v1.base_vector_query import DistanceMeasure
from google import genai
from google.genai import types

# --- 0. LOAD BIáº¾N MÃ”I TRÆ¯á»œNG ---
load_dotenv()

# --- 1. Cáº¤U HÃŒNH FASTAPI & CORS ---
app = FastAPI(title="FPTU RAG Backend")

# Cho phÃ©p Next.js gá»i API
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_methods=["*"],
    allow_headers=["*"],
)

# --- 2. KHá»I Táº O Dá»ŠCH Vá»¤ ---

# Káº¿t ná»‘i Firestore (Xá»­ lÃ½ thÃ´ng minh cho cáº£ Local vÃ  Deploy)
if not firebase_admin._apps:
    fb_config = os.getenv("FIREBASE_CONFIG")
    if fb_config:
        # Cháº¿ Ä‘á»™ Deploy (DÃ¹ng chuá»—i JSON trong Env)
        cred = credentials.Certificate(json.loads(fb_config))
    else:
        # Cháº¿ Ä‘á»™ Local (DÃ¹ng file váº­t lÃ½)
        cred_path = os.getenv("FIREBASE_SERVICE_ACCOUNT", "service-account.json")
        cred = credentials.Certificate(cred_path)
    firebase_admin.initialize_app(cred)

db = firestore.client()

# Khá»Ÿi táº¡o Gemini vÃ  Embedding Model
client = genai.Client(api_key=os.getenv("GEMINI_API_KEY"))
MODEL_ID = "gemini-2.5-flash"  # Báº¡n cÃ³ thá»ƒ Ä‘á»•i sang 1.5-flash náº¿u cáº§n
model_embed = SentenceTransformer('all-MiniLM-L6-v2')

# --- 3. MENU Äá»ŠNH TUYáº¾N (Dá»±a trÃªn module NLP cá»§a báº¡n) ---
SEARCH_KEYS_MENU = {
    "V1": "thi tiáº¿ng anh Ä‘áº§u vÃ o, xáº¿p lá»›p, ielts 6.0, miá»…n há»c dá»± bá»‹, cáº¥u trÃºc Ä‘á» thi, writing skill",
    "V2": "lá»™ trÃ¬nh luk global, hurricane, greenfire, heatwave, thunderbolt, debate, thuyáº¿t trÃ¬nh",
    "V3": "summit 1 summit 2, top notch, progress test pt, assignment mÃ´n ent, thi seb eos",
    "V4": "máº¹o pass mÃ´n tiáº¿ng anh, cÃ¡ch dÃ¹ng edunext fap, kiá»ƒm tra Ä‘iá»ƒm danh, writing speaking assignment",
    "V5": "há»c nháº¡c cá»¥ dÃ¢n tá»™c, Ä‘Ã n báº§u, Ä‘Ã n tranh, sÃ¡o trÃºc, Ä‘á»‹a chá»‰ mua nháº¡c cá»¥ háº£o vÄ©nh Ä‘Ã  náºµng",
    "V6": "há»c vovinam fpt, clb vovinam vvc, thi lÃªn Ä‘ai, vÃµ nháº¡c, giáº£i khÆ¡i nguá»“n vÃµ viá»‡t",
    "V7": "kinh nghiá»‡m Ä‘i quÃ¢n sá»±, Ä‘á»“ dÃ¹ng tÃ¢n binh, lÃ³t giÃ y, pháº¥n rÃ´m, gáº¥p chÄƒn bÃ¡nh chÆ°ng, ná»™i vá»¥",
    "V8": "review campus fpt Ä‘Ã  náºµng, tÃ²a nhÃ  alpha gamma, thÆ° viá»‡n, fpt city ngÅ© hÃ nh sÆ¡n",
    "V9": "so sÃ¡nh kÃ½ tÃºc xÃ¡ vÃ  trá», Æ°u nhÆ°á»£c Ä‘iá»ƒm ktx fpt, an ninh ná»™i trÃº, chi phÃ­ á»Ÿ trá»",
    "V10": "cáº©m nang thuÃª trá» Ä‘Ã  náºµng, lá»«a Ä‘áº£o tiá»n cá»c, há»£p Ä‘á»“ng thuÃª nhÃ , tÃ¬m báº¡n á»Ÿ ghÃ©p",
    "V11": "quÃ¡n Äƒn ngon fpt Ä‘Ã  náºµng, cafe há»c bÃ i, zone six 24/7, cÆ¡m gÃ  xáº£ xá»‡, bÃºn Ä‘áº­u 1996",
    "V12": "link fap flm, táº£i pháº§n má»m thi seb eos, lá»—i ká»¹ thuáº­t, checkout e360, cÃ i Ä‘áº·t pháº§n má»m",
    "V13": "quáº£n lÃ½ thá»i gian, thÃ³i quen ngá»§, xem trÆ°á»›c bÃ i, check attendance fap, ká»¹ nÄƒng tá»± há»c"
}


# --- 4. Cáº¤U TRÃšC Dá»® LIá»†U ---
class ChatMessage(BaseModel):
    role: str
    content: str


class ChatRequest(BaseModel):
    message: str
    history: Optional[List[ChatMessage]] = []


# --- 5. LOGIC Xá»¬ LÃ CHÃNH ---

def get_semantic_search_query(user_raw_query, history):
    """Router: DÃ¹ng LLM chá»n bá»™ Key tá»‘i Æ°u tá»« Menu"""
    menu_str = "\n".join([f"- {k}: {v}" for k, v in SEARCH_KEYS_MENU.items()])

    context_recent = ""
    if history:
        context_recent = f"Ngá»¯ cáº£nh lá»‹ch sá»­: {history[-1].content}"

    prompt = f"""Báº¡n lÃ  bá»™ Ä‘á»‹nh tuyáº¿n dá»¯ liá»‡u cho sinh viÃªn FPTU.
    Nhiá»‡m vá»¥: PhÃ¢n tÃ­ch cÃ¢u há»i vÃ  chá»n ra Bá»˜ KEYWORD phÃ¹ há»£p nháº¥t.
    DANH SÃCH KEYWORDS:
    {menu_str}
    {context_recent}
    CÃ‚U Há»I NGÆ¯á»œI DÃ™NG: "{user_raw_query}"
    YÃŠU Cáº¦U: CHá»ˆ TRáº¢ Vá»€ chuá»—i keyword tÆ°Æ¡ng á»©ng hoáº·c cÃ¢u há»i gá»‘c. KhÃ´ng giáº£i thÃ­ch."""

    try:
        response = client.models.generate_content(model=MODEL_ID, contents=prompt)
        return response.text.strip()
    except:
        return user_raw_query


@app.post("/chat")
async def chat_endpoint(req: ChatRequest):
    try:
        # BÆ¯á»šC 1: ROUTING
        search_query = get_semantic_search_query(req.message, req.history)
        print(f"ğŸ¯ Router Ä‘Ã£ chá»n: {search_query}")

        # BÆ¯á»šC 2: TRUY XUáº¤T VECTOR
        query_vector = model_embed.encode(search_query).tolist()
        results = db.collection("handbook_vectors").find_nearest(
            vector_field="embedding",
            query_vector=Vector(query_vector),
            distance_measure=DistanceMeasure.COSINE,
            limit=1
        ).get()

        if not results:
            return {"reply": "ğŸ¤– Bot: Xin lá»—i, mÃ¬nh khÃ´ng tÃ¬m tháº¥y dá»¯ liá»‡u liÃªn quan."}

        top_result = results[0]
        context = top_result.to_dict().get('content', 'KhÃ´ng cÃ³ ná»™i dung')
        dist = getattr(top_result, 'distance', 0) or 0
        print(f"ğŸ“Š Distance: {dist:.4f}")

        if dist > 0.6:
            return {"reply": "ğŸ¤– Bot: CÃ¢u há»i nÃ y náº±m ngoÃ i pháº¡m vi cáº©m nang sinh viÃªn FPTU."}

        # BÆ¯á»šC 3: GENERATION
        system_instruction = "Báº¡n lÃ  trá»£ lÃ½ áº£o thÃ´ng minh cho sinh viÃªn Äáº¡i há»c FPT ÄÃ  Náºµng. Tráº£ lá»i thÃ¢n thiá»‡n, ngáº¯n gá»n, cÃ³ icon."

        response = client.models.generate_content(
            model=MODEL_ID,
            contents=f"THÃ”NG TIN Cáº¨M NANG: {context}\n\nCÃ‚U Há»I: {req.message}",
            config=types.GenerateContentConfig(
                system_instruction=system_instruction,
                temperature=0.4,
            )
        )

        return {"reply": response.text}

    except Exception as e:
        print(f"Lá»—i: {e}")
        raise HTTPException(status_code=500, detail=str(e))


if __name__ == "__main__":
    import uvicorn
    # Láº¥y port tá»« Render cáº¥p, náº¿u cháº¡y mÃ¡y nhÃ  thÃ¬ dÃ¹ng 8000
    port = int(os.environ.get("PORT", 8000))
    # Nhá»› Ä‘á»ƒ host="0.0.0.0" Ä‘á»ƒ Render quÃ©t Ä‘Æ°á»£c cá»•ng nhÃ©
    uvicorn.run(app, host="0.0.0.0", port=port)